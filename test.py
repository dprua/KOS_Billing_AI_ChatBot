import streamlit as st
import os
import json
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import logging
import urllib.parse
import base64
import re

# Azure SDK imports
from azure.storage.blob import BlobServiceClient, BlobClient
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.models import VectorizedQuery
from azure.core.credentials import AzureKeyCredential
from openai import AzureOpenAI
import tiktoken
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ê°œë°œí™˜ê²½ì—ì„œë§Œ, Azureì—ì„œëŠ” App Settings ì‚¬ìš©)
# if os.path.exists('.env'):

load_dotenv()

class Config:
    # Azure OpenAI ì„¤ì •
    AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
    AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY")
    AZURE_OPENAI_API_VERSION = "2024-02-01"
    CHAT_MODEL = "gpt-4o-mini-dprua"
    EMBEDDING_MODEL = "text-embedding-3-small"
    
    # Azure AI Search ì„¤ì •
    SEARCH_SERVICE_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
    SEARCH_API_KEY = os.getenv("AZURE_SEARCH_KEY")
    SEARCH_INDEX_NAME = "rag-1757924013216"
    
    # Azure Blob Storage ì„¤ì •
    BLOB_CONNECTION_STRING = os.getenv("AZURE_BLOB_CONNECTION_STRING")
    BLOB_CONTAINER_NAME = "project-documents"
    
    # í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    @classmethod
    def validate_config(cls):
        required_vars = [
            'AZURE_OPENAI_ENDPOINT',
            'AZURE_OPENAI_KEY', 
            'SEARCH_SERVICE_ENDPOINT',
            'SEARCH_API_KEY',
            'BLOB_CONNECTION_STRING'
        ]
        
        missing_vars = [var for var in required_vars if not getattr(cls, var)]
        
        if missing_vars:
            st.error(f"ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_vars)}")
            st.stop()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AzureServices:
    """Azure ì„œë¹„ìŠ¤ ì—°ë™ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.openai_client = AzureOpenAI(
            api_key=Config.AZURE_OPENAI_KEY,
            api_version=Config.AZURE_OPENAI_API_VERSION,
            azure_endpoint=Config.AZURE_OPENAI_ENDPOINT
        )
        
        self.blob_service_client = BlobServiceClient.from_connection_string(
            Config.BLOB_CONNECTION_STRING
        )
        
        self.search_client = SearchClient(
            endpoint=Config.SEARCH_SERVICE_ENDPOINT,
            index_name=Config.SEARCH_INDEX_NAME,
            credential=AzureKeyCredential(Config.SEARCH_API_KEY)
        )
        
        self.search_index_client = SearchIndexClient(
            endpoint=Config.SEARCH_SERVICE_ENDPOINT,
            credential=AzureKeyCredential(Config.SEARCH_API_KEY)
        )

class DocumentProcessor:
    """ë¬¸ì„œ ì²˜ë¦¬ ë° ì¸ë±ì‹± í´ë˜ìŠ¤"""
    
    def __init__(self, azure_services: AzureServices):
        self.azure_services = azure_services
        self.tokenizer = tiktoken.encoding_for_model("gpt-4")
    
    def upload_document(self, file_content: bytes, filename: str, metadata: Dict) -> bool:
        """ë¬¸ì„œë¥¼ Blob Storageì— ì—…ë¡œë“œ"""
        try:
            blob_client = self.azure_services.blob_service_client.get_blob_client(
                container=Config.BLOB_CONTAINER_NAME,
                blob=filename
            )
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            metadata.update({
                "upload_date": datetime.now().isoformat(),
                "processed": "false"
            })
            
            blob_client.upload_blob(
                file_content,
                metadata=metadata,
                overwrite=True
            )
            
            logger.info(f"Document uploaded successfully: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"Error uploading document: {str(e)}")
            return False
    
    def extract_text_from_document(self, file_content: bytes, file_type: str) -> str:
        """ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í™•ì¥ ê°€ëŠ¥)"""
        try:
            if file_type.lower() in ['txt']:
                return file_content.decode('utf-8')
            elif file_type.lower() in ['pdf']:
                # PDF ì²˜ë¦¬ ë¡œì§ (PyPDF2, pdfplumber ë“± ì‚¬ìš©)
                return "PDF ì²˜ë¦¬ ê¸°ëŠ¥ êµ¬í˜„ í•„ìš”"
            elif file_type.lower() in ['docx']:
                # Word ë¬¸ì„œ ì²˜ë¦¬ ë¡œì§ (python-docx ì‚¬ìš©)
                return "DOCX ì²˜ë¦¬ ê¸°ëŠ¥ êµ¬í˜„ í•„ìš”"
            # elif file_type.lower() in ['csv']:
            #     # Word ë¬¸ì„œ ì²˜ë¦¬ ë¡œì§ (python-docx ì‚¬ìš©)
                return "DOCX ì²˜ë¦¬ ê¸°ëŠ¥ êµ¬í˜„ í•„ìš”"
            else:
                return file_content.decode('utf-8', errors='ignore')
        except Exception as e:
            logger.error(f"Error extracting text: {str(e)}")
            return ""
    
    def chunk_text(self, text: str, max_tokens: int = 1000) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        sentences = text.split('.')
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            test_chunk = current_chunk + sentence + "."
            if len(self.tokenizer.encode(test_chunk)) <= max_tokens:
                current_chunk = test_chunk
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + "."
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            if not isinstance(text, str) or not text.strip():
                logger.error("Embedding input must be a non-empty string")
                return []
            
            response = self.azure_services.openai_client.embeddings.create(
                model=Config.EMBEDDING_MODEL,
                input=text
            )
            
            embedding = response.data[0].embedding
            
            # ì„ë² ë”©ì´ 2ì°¨ì› ë°°ì—´ë¡œ ë°˜í™˜ë˜ëŠ” ê²½ìš° 1ì°¨ì›ìœ¼ë¡œ í‰íƒ„í™”
            if isinstance(embedding, list) and isinstance(embedding[0], list):
                embedding = embedding[0]  # ì²« ë²ˆì§¸ ë°°ì—´ì„ ì„ íƒ
            
            return embedding
        except Exception as e:
            logger.error(f"Error getting embedding: {str(e)}")
            return []
        
    def index_document(self, filename: str, content: str, metadata: Dict) -> bool:
        """ë¬¸ì„œë¥¼ AI Searchì— ì¸ë±ì‹±"""
        try:
            chunks = self.chunk_text(content)
            documents = []
            
            for i, chunk in enumerate(chunks):
                embedding = self.get_embedding(chunk)
                if not embedding or not isinstance(embedding, list) or not all(isinstance(val, (int, float)) for val in embedding):
                    logger.warning(f"Invalid embedding for chunk {i}, skipping this chunk.")
                    continue
                
                import uuid
                doc_id = str(uuid.uuid4())
                document = {
                    "chunk_id": doc_id,
                    "filename": filename,
                    "chunk": chunk,
                    "text_vector": embedding,
                    "project_type": metadata.get("project_type"),  # ì´ë¯¸ ì˜ì–´
                    "technology": metadata.get("technology"),
                    "department": metadata.get("department")      # ì´ë¯¸ ì˜ì–´
                    # "chunk_index": i
                }
                documents.append(document)
        
            # AI Searchì— ë¬¸ì„œ ì—…ë¡œë“œ
            if documents:
                result = self.azure_services.search_client.upload_documents(documents)
                logger.info(f"Indexed {len(documents)} chunks for {filename}")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"Error indexing document: {str(e)}")
            return False

class ProjectAnalyzer:
    """ê³¼ì œ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, azure_services: AzureServices):
        self.azure_services = azure_services
    
    def search_similar_projects(self, query: str, top_k: int = 2) -> List[Dict]:
        """ìœ ì‚¬í•œ ê³¼ì œ ê²€ìƒ‰"""
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self._get_query_embedding(query)
            if not query_embedding:
                return []
            
            # ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
            vector_query = VectorizedQuery(
                vector=query_embedding,
                k_nearest_neighbors=top_k,
                fields="text_vector"
            )
            
            results = self.azure_services.search_client.search(
                search_text=query,
                vector_queries=[vector_query],
                select=["filename", "chunk", "project_type", "technology", "department"],
                top=top_k
            )

            similar_projects = []
            for result in results:
                print(result.get("@search.score", 0))
                similar_projects.append({
                    "filename": result.get("filename", ""),
                    "chunk": result.get("chunk", ""),
                    "project_type": result.get("project_type", ""),
                    "technology": result.get("technology", ""),
                    "department": result.get("department", ""),
                    "score": result.get("@search.score", 0)
                    # "upload_date": result.get("upload_date", "")
                })
            
            return similar_projects
            
        except Exception as e:
            logger.error(f"Error searching similar projects: {str(e)}")
            return []
    
    def _get_query_embedding(self, query: str) -> List[float]:
        """ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±"""
        try:
            response = self.azure_services.openai_client.embeddings.create(
                model=Config.EMBEDDING_MODEL,
                input=query
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Error getting query embedding: {str(e)}")
            return []
    
    def analyze_requirements(self, user_input: str, similar_projects: List[Dict]) -> str:
        """ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° ê°œë°œ ê¸°ëŠ¥ ì œì•ˆ"""
        try:
            # ìœ ì‚¬ ê³¼ì œ ì •ë³´ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
            context = self._build_context(similar_projects)
            
            system_prompt = """
            ë‹¹ì‹ ì€ KT ë¹Œë§ ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê°œë°œ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:
            
            1. ê°œë°œì´ í•„ìš”í•œ ì£¼ìš” ê¸°ëŠ¥ë“¤
            2. ìœ ì‚¬í•œ ê³¼ê±° í”„ë¡œì íŠ¸ì™€ì˜ ë¹„êµ ë¶„ì„
            
            ë‹µë³€ì€ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì‹œê³  ëª¨ë“  ë‹µë³€ì€ {context} ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. {context}ì— ì—†ëŠ” ë‚´ìš©ì€ ì‘ì„±í•˜ì§€ ë§ˆì‹œê³  {context} ì— ìƒí’ˆë ˆí¼ëŸ°ìŠ¤, ì²­êµ¬ë ˆí¼ëŸ°ìŠ¤ ë‚´ìš© ë° ìë°”ì†ŒìŠ¤ ê´€ë ¨ ë‚´ìš©ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì ì–´ì£¼ì„¸ìš”.
            
            """
            
            user_prompt = f"""
            ì‹ ê·œ ê°œë°œ ìš”êµ¬ì‚¬í•­:
            {user_input}
            
            ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ê³¼ê±° ìœ ì‚¬ í”„ë¡œì íŠ¸:
            {context}
            
            ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œë°œì´ í•„ìš”í•œ ê¸°ëŠ¥ê³¼ ê³¼ê±° í”„ë¡œì íŠ¸ì™€ì˜ ë¹„êµë¥¼ í¬í•¨í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”.
            conetextì— ìˆëŠ” ë‚´ìš©ë§Œ ì°¸ê³ í•˜ì„¸ìš”.
            """
            
            response = self.azure_services.openai_client.chat.completions.create(
                model=Config.CHAT_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            print(1)
            print(response)
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Error analyzing requirements: {str(e)}")
            return "ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _build_context(self, similar_projects: List[Dict]) -> str:
        """ìœ ì‚¬ í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        if not similar_projects:
            return "ê´€ë ¨ëœ ê³¼ê±° í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context = "=== ê³¼ê±° ìœ ì‚¬ í”„ë¡œì íŠ¸ ì •ë³´ ===\n\n"
        for i, project in enumerate(similar_projects, 1):
            context += f"í”„ë¡œì íŠ¸ {i}:\n"
            context += f"- íŒŒì¼ëª…: {project['filename']}\n"
            context += f"- í”„ë¡œì íŠ¸ ìœ í˜•: {project['project_type']}\n"
            context += f"- ê¸°ìˆ ìŠ¤íƒ: {project['technology']}\n"
            context += f"- ë‹´ë‹¹ë¶€ì„œ: {project['department']}\n"
            context += f"- ìœ ì‚¬ë„: {project['score']:.2f}\n"
            context += f"- ë‚´ìš©: {project['chunk'][:500]}...\n"
            context += "\n" + "="*50 + "\n\n"
        
        return context

class StreamlitApp:
    """Streamlit ì•± í´ë˜ìŠ¤"""
    
    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ ê²€ì¦
        Config.validate_config()
        
        self.azure_services = AzureServices()
        self.document_processor = DocumentProcessor(self.azure_services)
        self.project_analyzer = ProjectAnalyzer(self.azure_services)
    
    def run(self):
        st.set_page_config(
            page_title="KT ë¹Œë§ ê³¼ì œ ë¶„ì„ ì±—ë´‡",
            page_icon="ğŸ“‹",
            layout="wide"
        )
        
        st.title("ğŸ“‹ KT ë¹Œë§ ê³¼ì œ ë¶„ì„ ì±—ë´‡")
        st.markdown("---")
        
        # ì„œë¹„ìŠ¤ ìƒíƒœ ì²´í¬ (ì‚¬ì´ë“œë°” ë Œë”ë§ ì „)
        if not self._check_azure_services():
            st.error("âš ï¸ Azure ì„œë¹„ìŠ¤ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
        
        # ì‚¬ì´ë“œë°”
        self._render_sidebar()
        
        # ë©”ì¸ ì»¨í…ì¸  
        tab1, tab2 = st.tabs(["ê³¼ì œ ë¶„ì„", "ë¬¸ì„œ ì—…ë¡œë“œ"])
        
        with tab1:
            self._render_analysis_tab()
        
        with tab2:
            self._render_upload_tab()
    
    def _render_sidebar(self):
        st.sidebar.header("ì„¤ì •")
        
        # Azure ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        st.sidebar.subheader("ì„œë¹„ìŠ¤ ìƒíƒœ")
        if self._check_azure_services():
            st.sidebar.success("âœ… Azure ì„œë¹„ìŠ¤ ì—°ê²°ë¨")
        else:
            st.sidebar.error("âŒ Azure ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        
        # í†µê³„ ì •ë³´
        st.sidebar.subheader("ë¬¸ì„œ í†µê³„")
        total_docs = self._get_document_count()
        st.sidebar.metric("ì €ì¥ëœ ë¬¸ì„œ ìˆ˜", total_docs)
    
    def _render_analysis_tab(self):
        st.header("ê³¼ì œ ë¶„ì„")
        
        # ì‚¬ìš©ì ì…ë ¥
        with st.form("analysis_form"):
            project_title = st.text_input("í”„ë¡œì íŠ¸ ì œëª©", placeholder="ì˜ˆ: ëª¨ë°”ì¼ ë¹Œë§ ì‹œìŠ¤í…œ ê°œì„ ")
            
            requirements = st.text_area(
                "ê°œë°œ ìš”êµ¬ì‚¬í•­",
                height=200,
                placeholder="ìƒì„¸í•œ ê°œë°œ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”..."
            )
            
            submitted = st.form_submit_button("ë¶„ì„ ì‹œì‘", type="primary")
        
        if submitted and requirements:
            with st.spinner("ê³¼ì œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                # ìœ ì‚¬ í”„ë¡œì íŠ¸ ê²€ìƒ‰
                search_query = f"{project_title} {requirements}"
                similar_projects = self.project_analyzer.search_similar_projects(search_query)
                
                # ìš”êµ¬ì‚¬í•­ ë¶„ì„
                analysis_result = self.project_analyzer.analyze_requirements(
                    requirements, similar_projects
                )
                
                # ê²°ê³¼ í‘œì‹œ
                st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.subheader("ğŸ“‹ ë¶„ì„ ê²°ê³¼")
                    st.markdown(analysis_result)
                
                with col2:
                    st.subheader("ğŸ“š ìœ ì‚¬ ê³¼ì œ")
                    if similar_projects:
                        # ì˜ë¬¸ ì½”ë“œë¥¼ í•œêµ­ì–´ë¡œ ë³€í™˜
                        project_type_map = {
                            "billing_system": "ë¹Œë§ ì‹œìŠ¤í…œ",
                            "customer_management": "ê³ ê°ê´€ë¦¬", 
                            "settlement_system": "ì •ì‚° ì‹œìŠ¤í…œ",
                            "mobile_app": "ëª¨ë°”ì¼ ì•±",
                            "web_service": "ì›¹ ì„œë¹„ìŠ¤",
                            "data_analysis": "ë°ì´í„° ë¶„ì„",
                            "infrastructure": "ì¸í”„ë¼",
                            "security": "ë³´ì•ˆ",
                            "others": "ê¸°íƒ€"
                        }
                        
                        department_map = {
                            "development_team": "ê°œë°œíŒ€",
                            "planning_team": "ê¸°íšíŒ€",
                            "operations_team": "ìš´ì˜íŒ€",
                            "quality_assurance_team": "í’ˆì§ˆíŒ€",
                            "data_team": "ë°ì´í„°íŒ€",
                            "infrastructure_team": "ì¸í”„ë¼íŒ€", 
                            "security_team": "ë³´ì•ˆíŒ€",
                            "others": "ê¸°íƒ€"
                        }
                        
                        for i, project in enumerate(similar_projects[:2], 1):
                            with st.expander(f"ìœ ì‚¬ ê³¼ì œ {i} (ìœ ì‚¬ë„: {project['score']:.2f})"):
                                st.write(f"**íŒŒì¼ëª…:** {project['filename']}")
                                
                                project_type_kr = project_type_map.get(project['project_type'], project['project_type'])
                                department_kr = department_map.get(project['department'], project['department'])
                                
                                st.write(f"**í”„ë¡œì íŠ¸ ìœ í˜•:** {project_type_kr}")
                                st.write(f"**ê¸°ìˆ ìŠ¤íƒ:** {project['technology']}")
                                st.write(f"**ë‹´ë‹¹ë¶€ì„œ:** {department_kr}")
                                st.write(f"**ë‚´ìš©:** {project['chunk'][:500]}...")
                    else:
                        st.info("ìœ ì‚¬í•œ ê³¼ê±° ê³¼ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def _render_upload_tab(self):
        st.header("ë¬¸ì„œ ì—…ë¡œë“œ")
        
        with st.form("upload_form"):
            uploaded_file = st.file_uploader(
                "ê³¼ì œ ë¬¸ì„œ ì„ íƒ",
                type=['txt', 'pdf', 'docx', 'csv'],
                help="TXT, PDF, DOCX, CSV íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
            
            col1, col2 = st.columns(2)
            with col1:
                project_type = st.selectbox(
                    "í”„ë¡œì íŠ¸ ìœ í˜•",
                    ["Billing", "Order", "SETL"]
                )
                technology = st.text_input("ê¸°ìˆ ìŠ¤íƒ", placeholder="ì˜ˆ: Java, Spring, Oracle")
            
            with col2:
                department = st.selectbox(
                    "ë‹´ë‹¹ë¶€ì„œ",
                    ["DEV", "OPS", "QA"]
                )
            upload_submitted = st.form_submit_button("ì—…ë¡œë“œ", type="primary")
        
        if upload_submitted and uploaded_file:
            with st.spinner("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì¸ë±ì‹±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                metadata = {
                    "project_type": project_type,
                    "technology": technology,
                    "department": department
                }
                
                # íŒŒì¼ ì—…ë¡œë“œ
                file_content = uploaded_file.read()
                filename = uploaded_file.name
                
                # Blob Storageì— ì—…ë¡œë“œ
                upload_success = self.document_processor.upload_document(
                    file_content, filename, metadata
                )
                
                if upload_success:
                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì¸ë±ì‹±
                    file_type = filename.split('.')[-1]
                    content = self.document_processor.extract_text_from_document(
                        file_content, file_type
                    )
                    print(content)
                    if content:
                        index_success = self.document_processor.index_document(
                            filename, content, metadata
                        )
                        
                        if index_success:
                            st.success(f"âœ… '{filename}' ì—…ë¡œë“œ ë° ì¸ë±ì‹±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        else:
                            st.warning("âš ï¸ ì—…ë¡œë“œëŠ” ì™„ë£Œë˜ì—ˆì§€ë§Œ ì¸ë±ì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            # st.success(f"âœ… '{filename}' ì—…ë¡œë“œ ë° ì¸ë±ì‹±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.error("âŒ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.error("âŒ íŒŒì¼ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    def _check_azure_services(self) -> bool:
        """Azure ì„œë¹„ìŠ¤ ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            # ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸
            self.azure_services.blob_service_client.get_account_information()
            return True
        except:
            return False
    
    def _get_document_count(self) -> int:
        """ì €ì¥ëœ ë¬¸ì„œ ìˆ˜ ì¡°íšŒ"""
        try:
            container_client = self.azure_services.blob_service_client.get_container_client(
                Config.BLOB_CONTAINER_NAME
            )
            return len(list(container_client.list_blobs()))
        except:
            return 0

def main():
    try:
        app = StreamlitApp()
        app.run()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        logger.error(f"Application error: {str(e)}", exc_info=True)

if __name__ == "__main__":
    main()